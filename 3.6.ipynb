{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091ea62c",
   "metadata": {},
   "source": [
    "# 3.6 예제: 레스토랑 리뷰 감성 분류하기\n",
    "\n",
    "이 프로젝트는 리뷰와 감성 레이블(긍정 or 부정)이 쌍을 이루는 옐프 데이터셋을 사용합니다.  \n",
    "데이터를 정제하고, 훈련, 검증, 테스트 세트로 나누는 전처리 단계 및 몇가지를 추가로 설명하면서 프로젝트를 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112ee4a0",
   "metadata": {},
   "source": [
    "앞으로 매번 사용할 3개의 보조 클래스에 대해서 간단하게 설명해보면,  \n",
    "1. Vocabularay = 샘플과 타깃의 인코딩에서 설명한 정수와 토큰 매핑을 수행\n",
    "2. Vectorizer = 어휘 사전을 캡슐화 하고 리뷰 텍스트 같은 문자열 데이터를 훈련과정에서 사요할 수치 벡터로 전환.\n",
    "3. DataLoader = 개별 벡터 데이터 포인트를 미니 배치로 모으는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bb292",
   "metadata": {},
   "source": [
    "# 3.6.1 옐프 리뷰 데이터셋\n",
    "\n",
    "해당 프로젝트에서는 데이터셋의 훈련 샘플의 10%만 사용합니다. (Light version)   \n",
    "이렇게 작은 데이터셋을 사용하면 훈련과 테스트가 빨라지지만 전체 데이터셋을 사용할 때 보다 낮은 정확도를 가집니다.\n",
    "\n",
    "데이터셋을 훈련,검증,테스트용으로 나눌겁니다.  \n",
    "훈련세트로 모델을 훈련하고, 검증세트로 모델이 얼마나 잘 작동하는지 평가합니다.  \n",
    "검증 세트를 기반으로 모델을 선택하게 되면 물가피하게 모델이 검증세트에 더 잘 수행되도록 편향되기 때문에 모델이 점차 개선되는지 재평가 해보기 위해서 세번째 세트인 평가세트를 활용해서 이 문제를 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287f61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0fcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "args = Namespace(\n",
    "    raw_train_dataset_csv = \"raw_train.csv\",\n",
    "    raw_test_dataset_csv = \"raw_test.csv\",\n",
    "    proportion_subset_of_train = 0.1,\n",
    "    train_proportion = 0.7,\n",
    "    val_proportion = 0.15,\n",
    "    test_proportion = 0.15,\n",
    "    output_munged_csv = \"reviews_with_splits_lite.csv\",\n",
    "    seed = 1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae1812",
   "metadata": {},
   "source": [
    "인자와 부속명령을 위한 명령행 옵션인, argparse를 활용해서 파이썬 내부에서 파일을 다운받고, 데이터를 나누어 줄 수 있습니다.  \n",
    "train 70%, validation 15%, test 15%로 데이터를 분할할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d137460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터를 읽습니다.\n",
    "train_reviews = pd.read_csv(args.raw_train_dataset_csv, header=None, names=['rating', 'review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcd2ab",
   "metadata": {},
   "source": [
    "다운받은 원본데이터를 파이썬에서 활용하기 위해 train_reviews 변수에 데이터를 읽어주고 컬럼명을 rating과 review 로 지정해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808fc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 클래스 비율이 동일하도록 만듭니다.\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in train_reviews.iterrows():\n",
    "    by_rating[row.rating].append(row.to_dict())\n",
    "    \n",
    "review_subset = []\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "    n_total = len(item_list)\n",
    "    n_subset = int(args.proportion_subset_of_train * n_total)\n",
    "    review_subset.extend(item_list[:n_subset])\n",
    "    \n",
    "review_subset = pd.DataFrame(review_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0334c",
   "metadata": {},
   "source": [
    "review_subset에 존재하는 데이터에서 10% 에 해당하는 데이터만 따로 저장해준다.  \n",
    "그리고 defaultdic메서드를 활용해서 클래스별로 비율이 동일하도록 만들어 준 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387006ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wing sauce is like water. Pretty much a lot of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Owning a driving range inside the city limits ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0       1  Unfortunately, the frustration of being Dr. Go...\n",
       "1       1  I don't know what Dr. Goldberg was like before...\n",
       "2       1  I'm writing this review to give you a heads up...\n",
       "3       1  Wing sauce is like water. Pretty much a lot of...\n",
       "4       1  Owning a driving range inside the city limits ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898f11d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    280000\n",
       "2    280000\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb8033",
   "metadata": {},
   "source": [
    "앞에서 클래스별로 비율이 동일하도록 만들어준 결과값입니다. (클래스별로 각각 28000개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbaa64c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유 클래스\n",
    "set(review_subset.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08ab6d",
   "metadata": {},
   "source": [
    "클래스는 1과 2로 나누어지는 것을 볼 수 있다.  \n",
    "1은 negative, 2는 positive 클래스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfeb65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-12 훈련,검증,테스트 세트 만들기\n",
    "\n",
    "# 별점 기준으로 나누어, 훈련, 검증, 테스트를 만듭니다.\n",
    "by_rating = collections.defaultdict(list)\n",
    "for _, row in review_subset.iterrows():\n",
    "    by_rating[row.rating].append(row.to_dict())\n",
    "    \n",
    "# 분할 데이터를 만듭니다.\n",
    "final_list = []\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "for _, item_list in sorted(by_rating.items()):\n",
    "    np.random.shuffle(item_list)\n",
    "    n_total = len(item_list)\n",
    "    n_train = int(args.train_proportion * n_total)\n",
    "    n_val = int(args.val_proportion * n_total)\n",
    "    n_test = int(args.test_proportion * n_total)\n",
    "    \n",
    "    # 데이터 포인트에 분할 속성을 추가합니다.\n",
    "    for item in item_list[:n_train]:\n",
    "        item['split'] = 'train'\n",
    "    \n",
    "    for item in item_list[n_train:n_train+n_val]:\n",
    "        item['split'] = 'val'\n",
    "        \n",
    "    for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
    "        item['split'] = 'test'\n",
    "        \n",
    "    # 최종 리스트에 추가합니다.\n",
    "    final_list.extend(item_list)\n",
    "    \n",
    "# 분할 데이터를 데이터 프레임으로 만듭니다.\n",
    "final_reviews = pd.DataFrame(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99aaf15",
   "metadata": {},
   "source": [
    "앞서 나왔던 args에서 지정한 7:1.5:1.5 비율로 각각 데이터를 train/val/test로 지정했고, 최종 리스트에 추가해주었다.\n",
    "\n",
    "리스트형태의 데이터를 분석에 용이한 pandas 데이터 프레임으로 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7baeb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    39200\n",
       "val       8400\n",
       "test      8400\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b36eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-13 최소한의 데이터 정제 작업\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "final_reviews.review = final_reviews.review.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d411a",
   "metadata": {},
   "source": [
    "최소한의 데이터 정제작업을 거친다.  \n",
    "정규식을 활용하여 기호 앞뒤에 공백을 넣고, 구두점이 아닌 기호를 제거하는 정제작업을 진행해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b61dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reviews['rating'] = final_reviews.rating.apply({1: 'negative', 2: 'positive'}.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab6af59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                                             review  split\n",
       "0  negative  terrible place to work for i just heard a stor...  train\n",
       "1  negative   hours , minutes total time for an extremely s...  train\n",
       "2  negative  my less than stellar review is for service . w...  train\n",
       "3  negative  i m granting one star because there s no way t...  train\n",
       "4  negative  the food here is mediocre at best . i went aft...  train"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061272f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reviews.to_csv(args.output_munged_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58dada",
   "metadata": {},
   "source": [
    "# 3.6.2 파이토치 데이터셋 이해하기\n",
    "\n",
    "해당 프로젝트는 pytorch 프레임워크를 기반으로 진행된다. 그리고 클래스 객체를 활용해서 주요한 파이프라인을 수행하게 된다.  \n",
    "또한 파이토치는 Dataset, DataLoader를 활용하여 데이터의 형태를 변환시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ea100",
   "metadata": {},
   "source": [
    "ReviewDataset 클래스는 데이터셋이 최소한으로 정제되고 3개로 나뉘었다고 가정한다.  \n",
    "특히 해당 데이터셋은 공백을 기준으로 나눠서 토큰 리스트를 얻을 수 있다고 가정합니다.  \n",
    "샘플이 훈련, 검증, 테스트 중 어느세트에 있는지 표시되었다고 가정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a2a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임포트\n",
    "\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7a19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-14 옐프 리뷰 데이터를 위한 파이토치 데이터셋 클래스\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    # 클래스 인스턴스 생성시 초기화 하면서 실행되는 부분\n",
    "    # self란? 인스턴스(클래스에 의해 만들어진 객체) 자기 자신을 의미,\n",
    "    # self 가 있는 것이 인스턴스 변수\n",
    "    def __init(self, review_df, vectorizer):\n",
    "        \"\"\"\n",
    "        매개변수 : \n",
    "            review_df (pands.DataFrame) : 데이터셋\n",
    "            vectorizer (ReviewVectorizer) : ReviewVectorizer 객체\n",
    "        \"\"\"\n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df = self.review_df[self.review_df.split == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val = self.review_df[self.review_df.split == 'val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.review_df[self.review_df.split == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self._lookup_dict = {'train' : (self.train_df, self.train_size),\n",
    "                             'val' : (self.val_df, self.validation_size),\n",
    "                             'test' : (self.test_df, self.test_size)}\n",
    "        \n",
    "        self.set_spilt('train')\n",
    "    \n",
    "    # 클래스 메소드 (데코레이터 사용) = 클래스 변수를 컨트롤 할 때 사용된다.\n",
    "    # cls 인자를 받음. cls란? ReviewDataset 클래스를 뜻함.\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
    "        \"\"\"데이터셋을 로드하고 새로운 ReviewVectorizer 객체를 만듭니다.\n",
    "        캐시된 ReviewVectorizer 객체를 재사용할 때 사용합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            review_csv (str): 데이터셋의 위치\n",
    "            vectorizer_filepath (str): ReviewVectorizer 객체의 저장위치\n",
    "        반환값:\n",
    "            ReviewDataset의 인스턴스\n",
    "        \"\"\"\n",
    "        \n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(review_df, vectorizer)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"파일에서 Reviewvectorizer 객체를 로드하는 정적 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer_filepath (str) : 직렬화된 ReviewVectorizer 객체의 위치\n",
    "        반환값:\n",
    "            ReviewVectorizer의 인스턴스\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
    "    \n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"ReviewVectorizer 객체를 json 형태로 디스크에 저장합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer_filepath (str) : ReviewVectorizer 객체의 저장위치\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._traget_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            index (int): 데이터 포인트의 인덱스\n",
    "        반환값:\n",
    "            데이터 포인트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        review_vector = \\\n",
    "            self._vectorizer.vectorize(row.review)\n",
    "        \n",
    "        rating_index = \\\n",
    "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "        \n",
    "        return {'x_data' : review_vector,\n",
    "                 'y_target' : rating_index}\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            batch_size (int)\n",
    "        반환값:\n",
    "            배치 개수\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd40b64",
   "metadata": {},
   "source": [
    "1. 파이토치에서 새로운 데이터셋을 사용하려면 먼저 Dataset 클래스를 상속하여 __getitem__(), __len__() 메서드를 구현해야한다.  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "2. 해당 클래스 안에는 다양한 파이토치 유틸리티를 사용하는데, DataLoader / ReviewVectorizer과 같은 클래스는 아래에 나온다. (클래스들은 서로 크게 의존한다.)  \n",
    "    ReviewVectorizer => 리뷰텍스트를 수치로 변환하는 클래스\n",
    "    DataLoader => 데이터셋에서 샘플링하고 모아서 미니배치를 만드는 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe7cc3",
   "metadata": {},
   "source": [
    "### Dataset 클래스를 상속한다는 뜻이 무엇일까?\n",
    "\n",
    "torch.utils.data.Dataset은 데이터셋을 나타내는 '추상 클래스'이다.  \n",
    "우리만의 데이터셋은 Dataset에 상속하고, 아래와 같이 오버라이드 해야한다.  \n",
    "    len(dataset)에서 호출되는 __len__은 데이터셋의 크기를 리턴한다.  \n",
    "    dataset[i]에서 호출되는 __getitem__은 i번째 샘플을 찾는데 사용된다.  \n",
    "    즉, __init__을 통해 데이터를 처리해서 가져오지만, __getitem__을 이용해서 데이터를 하나씩 판독한다.  \n",
    "    그리고 최정 리턴값은{'x_data':review_vector,'y_target':rating_index} 형태의 사전 형태를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242a282",
   "metadata": {},
   "source": [
    "### ReviewDataset 커스텀 데이터셋에 등장하는 함수 정리\n",
    "\n",
    "1. __init__(self, review_df,Vectorizer)  \n",
    "    데이터셋(review_df)  \n",
    "    벡터화해주는 객체 (vectorizer)  \n",
    "    train_df/train_size/val_df/val_size/test_df/test_size 변수를 정의\n",
    "\n",
    "2. @classmethod load_dataset_and_make_vectorizer(cls, review_csv)  \n",
    "    데이터셋을 로드하고 새로운 ReviewVectorizer 객체를 만들어주는 함수  \n",
    "    review_csv라는 데이터셋의 위치를 매개변수로 받는다.  \n",
    "    ReviewDataset(review_df, ReviewVectorizer.from_dataset(train_review_df)한 결과값을 반환  \n",
    "    reviewVectorizer.from_dataset는 데이터셋 데이터프레임에서 Vectorizer객체를 만드는 메서드  \n",
    "    반환값이 ReviewVectorizer 객체이다.\n",
    "    \n",
    "3. @staticmethod load_vectorizer_only(vectorizer_filepath)  \n",
    "    파일에서 ReviewVectorizer 객체를 로드하는 정적 메서드  \n",
    "    ReviewVectorizer.from_serializable(json.load(fp))를 반환한다.  \n",
    "    ReviewVectorizer.from_serializable는 직렬화된 딕셔너리(json.load(fp))에서 ReviewVectorizer 객체를 만드는 메소드  \n",
    "    \n",
    "4. save_vectorizer(seef, vectorizer_filepath)  \n",
    "    ReviewVectorizer 객체를 json 형태로 디스크에 저장하는 메소드  \n",
    "\n",
    "5. get_vectorizer(self)  \n",
    "    벡터 변환 객체를 반환하는 메서드 self._vectorizer 값을 반환\n",
    "    \n",
    "6. set_spilt(self, split=\"train\")  \n",
    "    데이터 프레임에 있는 열을 사용하여 분할 세트를 선택  \n",
    "    \"train\", \"test\",\"val\" 중 하나  \n",
    "\n",
    "7. __len__(self)  \n",
    "8. __getitem__(self, index)  \n",
    "    {\"x_data\" : review_vector, \"y_target\" : rating_index}로 이루어진 dic 형태로 반환  \n",
    "    \n",
    "9. get_num_batches(self, batch_size)  \n",
    "    배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7754dd",
   "metadata": {},
   "source": [
    "# 3.6.3 Vocabulary, Vectorizer, DataLoader 클래스  \n",
    "\n",
    "해당 예제는 위 세개의 클래스를 활용하여 중요한 파이프라인을 수행합니다.  \n",
    "텍스트의 입력을 벡터의 미니배치로 바꿔주기 위해 해당 클래스들을 사용합니다.  \n",
    "이 세개의 클래스는 각 토큰을 정수에 매핑하고, 이 매핑을 각 데이터포인트에 적용하여 벡터 형태로 변환해줍니다. 그 다음 벡터로 변환하 데이터 포인트를 모델을 위해 미니배치로 모은다.  \n",
    "전처리 된 데이터(텍스트)를 사용한다. (즉 데이터 포인트는 토큰화 된 집합이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd417aac",
   "metadata": {},
   "source": [
    "### Vocabulary 클래스\n",
    "\n",
    "머신러닝 파이프라인에 필요한 토큰과 정수 매핑을 관리하는 클래스  \n",
    "토큰과 정수로 매핑하는 크래스 (텍스트의 배치를 미니배치로 바꾸는 과정의 첫 단계)  \n",
    "토큰과 정수 사이를 1:1 매핑하는 방법 (반대로 매핑하는 경우까지, 총 딕셔너리 두개 필요)  \n",
    "두 딕셔너리를 Vocabulary 클래스에 캡슐화 한 것  \n",
    "훈련 데이터셋에 없는 단어는 UNK(Unknown)으로 처리  \n",
    "자주 등장하지 않는 토큰들을 제한해줌 => 이런 토큰들이 UNK로 처리되는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d7f10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
    "    \n",
    "    def __init(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
    "            add_unk (bool): UNK 토큰을 추가할지 지정하는 플래그\n",
    "            unk_token (str): Vocabulary에 추가할 UNK 토큰\n",
    "        \"\"\"\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_token = token_to_idx\n",
    "        \n",
    "        self._idx_to_token = {idx: token\n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다.\"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx,\n",
    "                 'add_unk': self._add_unk,\n",
    "                 'unk_token': self._unk_token}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"직렬화 된 딕셔너리에서 Vocabulary 객체를 만듭니다.\"\"\"\n",
    "        return cls(**contents)\n",
    "    \n",
    "    # 새로운 토큰을 추가하기 위한 함수\n",
    "    def add_token(self, token):\n",
    "        \"\"\"토큰을 기반으로 매핑 딕셔너리를 업데이트합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): Vocabulary에 추가할 토큰\n",
    "        반환값:\n",
    "            index (int): 토큰에 상응하는정수\n",
    "            \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
    "        매개변수:\n",
    "            tokens (list): 문자열 토큰 리스트\n",
    "        반환값:\n",
    "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "    \n",
    "    # 토큰에 해당하는 인덱스를 추출하기 위한 함수\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
    "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): 찾을 토큰\n",
    "        반환값:\n",
    "            index (int): 토큰에 해당하는 인덱스\n",
    "        노트:\n",
    "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
    "            'unk_index'가 0보다 커야 합니다.\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "        \n",
    "    #인덱스에 해당하는 토큰을 추출하기 위한 함수\n",
    "    def lookup_ind(self, index):\n",
    "        \"\"\"인덱스에 해당하는 토큰을 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            index (int): 찾을 인덱스\n",
    "        반환값:\n",
    "            token (str): 인덱스에 해당하는 토큰\n",
    "        에러:\n",
    "            keyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"Vocabulary에 인덱스(%d)가 없습니다.\" % index)\n",
    "        return self.idx_to_token[index]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa030e8",
   "metadata": {},
   "source": [
    "### Vocabulary 클래스에 등장하는 함수 정리\n",
    "\n",
    "1. __init__(self, token_to_idx=None, add_unk=True, unk_token=\"UNK\"  \n",
    "    1. 매개변수 설명  \n",
    "    * token_to_idx(dict): 기존 토큰-인덱스 매핑 딕셔너리  \n",
    "    * add_unk (bool): UNK 토큰을 추가할지 지정하는 플래그  \n",
    "    * unk_token (str): Vocabulary에 추가할 UNK 토큰  \n",
    "    \n",
    "2. to_serializable(self)  \n",
    "    1. 직렬화 할 수 있는 딕셔너리를 반환  \n",
    "    * {'token_to_idx': self._token_to_idx,'add_unk': self._add_unk, 'unk_token': self._unk_token}형태  \n",
    "    \n",
    "3. @classmethod form_serializable(cls, contents)  \n",
    "    1. 직렬화된 딕셔너리에서 vocabulary 객체를 생성  \n",
    "    \n",
    "4. add_token(self, token)  \n",
    "    1. 새로운 토큰을 추가하기 위한 함수  \n",
    "    2. 토큰을 기반으로 매핑 딕셔너리를 업데이트해준다.  \n",
    "    3. 매개변수 token이 Vocabulary에 추가할 토큰이 된다.\n",
    "    4. return index: 토큰에 상응하는 인덱스가 반환값으로 출력\n",
    "    \n",
    "5. add_mamy(self, tokens)  \n",
    "    1. 토큰 리스트를 vocabulary에 추가  \n",
    "    2. tokens는 문자열 list\n",
    "    3. 반환값도 tokens에 상응하는 인덱스 값\n",
    "    \n",
    "6. lookup_token(self,token)  \n",
    "    1. 토큰에 댕ㅇ하는 인덱스를 추출하는 메서드  \n",
    "    2. 매개변수 token이 찾을 토큰이고  \n",
    "    3. 반환값은 token이 갖는 인덱스값\n",
    "    \n",
    "7. lookup_index(self, index)  \n",
    "    1. 인덱스에 대응하는 토큰을 찾는 메소드  \n",
    "    2. 매개변수 index가 찾을 인덱스  \n",
    "    3. 반환값은 index에 해당하는 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cf43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
